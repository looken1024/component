## 第一部分、分类

监督学习：只需要给定输入样本集，机器就可以从中推演出指定目标变量的可能结果。

一般使用两种类型的目标变量：标称型和数值型。

### 1、机器学习基础

地震预测

从海量数据中抽取到有价值的信息将是一个非常重要的课题。

训练集：已分类数据，用于训练机器学习算法的数据样本集合

目标变量：机器学习算法的预测结果，分类算法中通常是离散型的，而在回归算法中通常是连续型的

训练数据

测试数据

精确度：测试样本预测的目标变量值与实际样本类别之间的差别

回归：预测数值型数据

监督学习：包含分类和回归

非监督学习：没有类别信息，也没有目标值
    聚类：数据集合分成由类似的对象组成的多个类的过程
    密度估计：寻找描述数据统计值的过程

监督学习：
    k近邻算法：线性回归
    朴素贝叶斯算法：局部加权线性回归
    支持向量机：Ridge回归
    决策树：Lasso最小回归系数估计

无监督学习：
    k均值：最大期望算法
    DBSCAN：Parzen窗设计

机器学习步骤：
    1、收集数据
    2、准备输入数据
    3、分析输入数据
    4、测试算法
    5、使用算法


### 2、k近邻算法

采用测量不同特征值之间的距离方法进行分类

优点：精度高，对异常值不敏感，无数据输入假定

缺点：计算复杂度高，空间复杂度高，适用数据范围：数值型和标称型

k近邻算法的一般流程：
    1、收集数据：可以使用任何方法
    2、准备数据：距离计算所需要的数值，最好是结构化的数据格式
    3、分析数据：可以使用任何方法
    4、训练算法：此步骤不适用于k近邻算法
    5、测试算法：计算错误率
    6、使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理

```python
from numpy import *
import operator

def createDataSet():
    group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])
    labels = ['A', 'A', 'B', 'B']
    return group, labels

def classify0(inX, dataSet, labels, k):
    dataSetSize = dataSet.shape([0])
    # 以下三行 距离计算
    diffMat = tile(inX, (dataSetSize, 1)) - dataSet
    sqDiffMat = diffMat ** 2
    sqDistances = sqDiffMat.sum(axis = 1)
    distances = sqDistances ** 0.5
    sortedDistIndicies = distances.argsort()
    classCount = {}
    # 以下两行 选择距离最小的k个点
    for i in range(k):
        woteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1

    sortedClassCount = sorted(classCount.iteritems(), key = operator.itemgetter(1), reverse = True)
    return sortedClassCount[0][0]

```



